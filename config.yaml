aliases:
  coder30: ollama/qwen3-coder:30b
  deepseek: nvidia/deepseek-ai/deepseek-v3.2
  gemini: google/gemini-3-pro-preview
  glm5: nvidia/z-ai/glm5
  grok: xai/grok-4
  pro: google/gemini-2.5-pro
  q30: ollama/qwen3:30b
  q8: ollama/qwen3:8b
  qwen480: nvidia/qwen/qwen3-coder-480b-a35b-instruct
gateway:
  api_key: AIzaSyC_kM2bTjauE5wGoQSGDf7oX-pJEgki8ZA
  model: gemini-2.5-flash
  provider: google
models:
  auto_fallback: true
  error_threshold: 3
  fallback_model: qwen3:8b
  fallback_provider: ollama
  primary_model: gemini-2.5-flash
  primary_provider: google
  recovery_time_seconds: 300
  # New Galactic AI features:
  streaming: true              # Stream Ollama responses in real-time to web UI
  context_window_trim: true    # Auto-trim history when approaching Ollama context limit
  smart_routing: false         # Set to true to enable task-based auto model routing
paths:
  logs: ./logs
  plugins: ./plugins
  watch: ./watch
  workspace: C:\Users\Chesley\.openclaw\workspace
providers:
  anthropic:
    apiKey: sk-ant-api03-yM-3Wq0PzM3_Xm90jYx_Wj50X_Xm90jYx_Wj50X_Xm90jYx_Wj50X_Xm90jYx_Wj50X-Xm90jYx
    baseUrl: https://api.anthropic.com/v1
  google:
    apiKey: AIzaSyC_kM2bTjauE5wGoQSGDf7oX-pJEgki8ZA
    baseUrl: https://generativelanguage.googleapis.com/v1beta
  nvidia:
    baseUrl: https://integrate.api.nvidia.com/v1
    keys:
      deepseek: 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
      glm: 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
      kimi: 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
      qwen: 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
      stepfun: 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
  ollama:
    baseUrl: http://127.0.0.1:11434/v1
  xai:
    apiKey: ai-gsA3iv3aFBmJ4n37SCD4rEpnALmOMCNkrstHbWYEhdijVyy61J936nScejw60rvQDrjThKNCpbEads4N
    baseUrl: https://api.x.ai/v1
# Browser engine configuration (Galactic Exclusive)
browser:
  engine: chromium    # chromium | firefox | webkit
  headless: false     # Set to true for server/headless environments

shell_tasks:
- command: adb devices
  name: ADB Check
- command: tasklist | findstr python
  name: Watchdog Status
system:
  heartbeat_interval: 5
  name: Galactic AI
  port: 9999
  version: 0.6.0-Alpha
telegram:
  admin_chat_id: 6790828435
  bot_token: 8012002164:AAF6NQT-7JZ2951dAlR2Mvm1pCEbK1A7DBs
web:
  enabled: true
  host: 127.0.0.1
  password_hash: 16c13d49e42cd306faa482fe68cef34ed189d6b1cf62c8e035598d096e6e539d
  port: 17789
