# Changelog ‚Äî Galactic AI

All notable changes to Galactic AI are documented here.

---

## v1.3.0 ‚Äî The Intelligence Update (2026-03-02)

### Added
- **`grep_search` Tool**: Powerful recursive file content searching with regex support. Allows the AI to navigate even the largest codebases by searching for function calls, variable usages, or logic patterns.
- **`code_outline` Tool**: Native Python AST parsing to show the structure of files (classes, functions, methods) with line numbers, enabling precise navigation.
- **Advanced Agentic Protocol**: Replaced the basic tool instructions with a comprehensive Research ‚Üí Plan ‚Üí Implement ‚Üí Verify methodology in `SOUL.md`.
- **Few-Shot Intelligence Examples**: Updated system prompt templates with clear examples of how to use deep-research tools strategically.

### Fixed
- **Ollama Thinking Injection**: Fixed a bug where `reasoning_effort` was being sent to Ollama (causing 400 errors). It now correctly injects `"think": true` into Ollama's `options` payload.
- **Metadata Synchronization**: Fixed a bug where Telegram and the Control Deck were showing different thinking levels; now both read from a single gateway source.
- **Skill Categorization**: Fixed missing category metadata in community skills (e.g., Gemini CLI) preventing them from showing up correctly in UI menus.

---

## v1.2.1 ‚Äî The Control Update (2026-02-27)

### Added
- **Centralized Model Manager**: Replaced massive hardcoded model lists across `web_deck.py` and `telegram_bridge.py` with a single source of truth: `config/models.yaml`.
- **Dynamic UI Loading**: The Control Deck and Telegram Bridge now dynamically fetch and render models from `models.yaml`, allowing users to easily add new models, edit names, or set `enabled: false` to hide them without modifying code.
- **OpenClaw Provider Parity**: Scanned the OpenClaw codebase and added support for 14 new AI providers to `models.yaml` (including MiniMax, Xiaomi, Moonshot, Qwen Portal, Qianfan, Together AI, HuggingFace, vLLM, Doubao, BytePlus, Cloudflare AI Gateway, Amazon Bedrock, Kilocode, and GitHub Copilot).
- **Custom Emojis**: Added visual styling and custom emojis to the Control Deck UI for all the newly integrated OpenClaw providers.
- **OpenRouter Tiers Restored**: Restored the "kickass assortment" of 26 OpenRouter models and re-implemented their categorizations (`openrouter-frontier`, `openrouter-strong`, `openrouter-fast`) safely into the dynamic architecture.

### Fixed
- **Ollama Dynamic Injection**: Fixed a UI issue where automatically detected Ollama models were failing to render because the generic "Ollama" provider block wasn't present in the static YAML file.
- **Provider Settings Crash**: Fixed a critical frontend exception in the Control Deck Settings tab caused by missing `provider` attributes on dynamically loaded model objects.

---

## v1.2.0 ‚Äî The Hivemind Update (2026-02-26)

### Added
- **Resumable Workflows**: The agent now automatically saves its active state (`history`, `messages`, `active_plan`, `turn_count`) to `logs/runs/<uuid>/checkpoint.json` every 5 tool calls or immediately on failure.
- **`resume_workflow` tool**: New native tool that allows the AI (or user) to re-load an interrupted workflow state from a specific checkpoint UUID and continue execution seamlessly.
- **Mission Control Dashboard**: Added a new Resumable Workflows UI directly into the Web Deck's **Thinking** tab. You can view all saved checkpoints, see their timestamps and plan previews, and instantly resume them with a click.
- **Workspace Oracle (`plan_optimizer` skill)**: A new heuristic engine that allows the AI to simulate tool chains and preview execution costs (time/complexity) before committing to a massive subagent refactor.
- **Gemini CLI Bridge (`gemini_cli_bridge` skill)**: Integrates the native Node.js `@google/gemini-cli-core` into Galactic AI. Allows Galactic AI to spawn the official Gemini CLI in the background with `--yolo` mode for deep codebase interventions.
- **Superpowers Integration (`superpowers` skill)**: Fully ported Jesse Vincent's Superpowers cognitive workflows. Gives Galactic AI native access to advanced behavioral rulebooks like Test-Driven-Development (TDD), Systematic Debugging, and Socratic Brainstorming.
- **Planner Fallback Model**: Added multi-tier redundancy to the internal Architect agent. You can now configure `planner_fallback_provider` and `planner_fallback_model` in `config.yaml` or via the Web Deck UI. If the primary planner model hangs or hallucinates, it instantly re-spawns using the fallback model.

### Fixed
- **Anti-Hallucination Guardrails**: Updated the core system prompt to strictly forbid the AI from hallucinating success when spawning background subagents. It is now hardcoded to verify execution via `process_status` or by reading output files.
- **Planner Parsing Engine**: Replaced the fragile O(N^2) JSON extraction algorithm in `gateway_v2.py` with an O(N) stack-based parser. This prevents the event loop from hanging and crashing when an LLM outputs malformed nested curly braces.
- **Empty Response Hole**: Fixed a critical bug where OpenRouter cloud models returning data inside `refusal` or `reasoning_content` tags (instead of standard `content`) were being misidentified as empty strings, causing an infinite fallback loop.

### Changed
- **Unified Boot Splash**: Combined the classic "GALACTIC" block text and the "AUTOMATION" logo into a single unified 3D ANSI banner. The dynamic cyan-to-purple gradient now sweeps across the entire boot screen instead of just the bottom half.
- **Universal Tool Schemas**: Cloud models (GPT/Claude) now receive the exact same strict JSON tool-call examples and full parameter schemas as local Ollama models, greatly improving their ability to autonomously edit files.

---

## v1.1.9 ‚Äî Core Dependency Fix (2026-02-25)

### Fixed
- **Missing Dependencies:** Fixed `ModuleNotFoundError: No module named 'scheduler'` and other missing core file errors in the release packages. Added `scheduler.py`, `splash.py`, `autopatch.py`, and `fix_ollama.py` to the automated release pipeline.
- **Version Sync:** Refined version syncing across all documentation and core files.

---

## v1.1.8 ‚Äî Self-Healing Code & Workspace RAG (2026-02-25)

### Added
- **Self-Healing Code Execution (TDD):** Added `test_driven_coder` tool to the Gemini Coder skill. The AI can now write a Python script, automatically run it in a sandboxed subprocess, catch any traceback errors, and autonomously loop with Gemini to fix the code until it executes successfully.
- **Workspace Context Awareness (RAG):** Added `workspace_indexer` community skill. A background thread now continuously hashes, chunks, and embeds your `workspace/` files into ChromaDB. The AI can now use the `search_workspace` tool to semantically search your local codebase instantly.

---

## v1.1.7 ‚Äî Computer Use & Live Voice (2026-02-25)

### Added
- **Computer Use (Vision GUI Automation):** Added `computer_use` skill. The AI can now take a screenshot, use a vision model (like Gemini 2.5 Pro) to find the exact X,Y coordinates of an element based on a natural language description, and interact with it (click, double-click, right-click, hover). This enables automation of entirely unknown, non-web applications without brittle template matching.
- **Live Voice Mode:** Added a "Live Call" button (`üìû`) next to the chat input in the Control Deck. When active, AI responses are automatically played aloud via TTS. If you click the microphone to speak while the AI is talking, it instantly pauses the audio, listens to your interruption, and responds to your new input.
- **Dual-Brain UI Config:** Added the ability to select and configure the "Planner" (Big Brain) model directly from the web Control Deck (Settings tab) and the Telegram Bot (`/models` menu).

---

## v1.1.6 ‚Äî Strategic Planning & Deep Memory (2026-02-25)

### Added
- **Strategic Planner (Big Brain / Builder):** Completely rewrote the pre-planning phase in `gateway_v2.py`. Instead of a single API call, the Planner is now an isolated ReAct agent. If configured in `config.yaml` (`planner_model`, `planner_provider`), this "Big Brain" model will autonomously scan your codebase, read files, and investigate *before* writing the step-by-step plan for your primary "Builder" model to execute. Trigger explicitly with `/plan`.
- **Long-Term Vector Memory:** Added `memory_manager` community skill. Integrates ChromaDB for semantic search and permanent storage of facts, preferences, and plans. Tools: `store_memory`, `recall_memories`.
- **Gemini Coder Skill:** Added `gemini_coder` community skill. Uses the new `google-genai` SDK to provide a dedicated "Senior Dev" coding expert tool (`gemini_code`) for generating and debugging code.
- **Desktop Window Awareness:** Added `desktop_list_windows` and `desktop_focus_window` to `desktop_tool.py` (using `pygetwindow`), allowing the AI to reliably find and focus applications instead of relying solely on screenshots.
- **Browser Wait Tool:** Added `chrome_wait_for` to `chrome_bridge.py` and the extension, enabling the AI to wait for specific DOM elements or text to appear before interacting.
- **Automated Release Pipeline:** Added `scripts/release.py` and `build_release.ps1/sh` to automate the creation of sanitized, versioned release packages for Windows, macOS, and Linux, including SHA256 sums and release notes.

### Fixed
- **Browser Stable Identifiers:** Replaced sequential `ref_` IDs in the Chrome extension (`content.js`) with stable, hash-based signatures. Element IDs no longer change when the DOM updates, drastically improving click reliability on dynamic pages.
- **SPA Typing Support:** Fixed `contentEditable` typing in the Chrome extension. Now explicitly dispatches `beforeinput`, `insertText`, and `keyup` events to trigger React/Vue state updates on complex SPAs (e.g., activating the "Post" button on X.com).
- **Gateway LLM Guardrails:** Enhanced the `is_ollama` system prompt with strict retry and failure guardrails, matching the cloud models.
- **Circuit Breaker:** Modified the ReAct loop to force a hard `break` when the 3-failure circuit breaker trips, preventing infinite tool hallucination loops.
- **Skill Creator Imports:** Fixed the `create_skill` tool prompt to enforce the correct `from skills.base import GalacticSkill` import.

---

## v1.1.4 ‚Äî Telegram UX + Telemetry Modes (2026-02-24)

### Added
- Memory/restarts: **Conversation Auto-Recall** injection (community skill) for remember/earlier/last time questions. Tool: `conversation_auto_recall_status`.
- Memory/restarts: **Boot Recall Banner** (community skill) prints last N hot-buffer messages and writes `logs/conversations/boot_recall_banner.txt`. Tool: `boot_recall_show`.

### Changed
- Telegram `/status` now supports **lite vs full** output:
  - `/status` ‚Üí lite telemetry
  - `/status full` (also `--full` / `-f`) ‚Üí full telemetry

### Updated
- Telegram command menu description updated to reflect lite/full.
- `/help` updated to show both status modes.

---

## v1.1.3 ‚Äî Chrome Extension Parity (2026-02-23)

### Bug Fixes
- **contenteditable typing**: `performType()` in content.js now uses `document.execCommand('insertText')` for proper SPA support (X.com, Notion, Reddit compose work correctly)
- **screenshot visibility**: `chrome_screenshot` now saves JPEG to disk and returns an actual image to the LLM (not a text description)

### New Tools (11 added, 16 ‚Üí 27 total)
- `chrome_zoom` ‚Äî region screenshot for close inspection of UI elements
- `chrome_drag` ‚Äî click-drag interactions (sliders, reordering)
- `chrome_right_click` ‚Äî JS context menu trigger
- `chrome_triple_click` ‚Äî triple-click to select all text
- `chrome_upload` ‚Äî file upload via Chrome Debugger `DOM.setFileInputFiles`
- `chrome_resize` ‚Äî viewport resize with mobile/tablet/desktop presets
- `chrome_get_network_body` ‚Äî fetch full response body for a network request by ID
- `chrome_wait` ‚Äî wait N seconds between browser actions
- `chrome_gif_start` / `chrome_gif_stop` / `chrome_gif_export` ‚Äî GIF recorder with Pillow assembly
- `chrome_read_network` now includes `request_id` in each entry

---

## [v1.1.2] ‚Äî 2026-02-23

### Added
- **‚ö° Skills Ecosystem** ‚Äî Complete architectural evolution of the plugin system. New `GalacticSkill` base class with structured metadata (`skill_name`, `version`, `author`, `description`, `category`, `icon`, `is_core`) and `get_tools()` dynamic tool registration. All capabilities now live in self-contained skill classes instead of the gateway monolith
- **‚ö° 6 Core Skills Migrated** ‚Äî ShellSkill (1 tool), DesktopSkill (8 tools), ChromeBridgeSkill (16 tools), SocialMediaSkill (6 tools), SubAgentSkill (2 tools), BrowserProSkill (55 tools). 88 tool definitions extracted from `gateway_v2.py` into `skills/core/`
- **‚ö° AI Self-Authoring** ‚Äî Byte can write, validate, and load new community skills at runtime. Three new meta-tools: `create_skill` (AST-validated, instantly live), `list_skills` (rich metadata), `remove_skill` (safe unload + file delete). Skills saved to `skills/community/` and tracked in `registry.json`
- **‚ö° Community Skill Discovery** ‚Äî `skills/community/` directory auto-loaded from disk on startup. `registry.json` manifest tracks AI-authored and user-installed community skills
- **‚ö° Skills Tab in Control Deck** ‚Äî Replaces Plugins tab with rich skill cards: icon, display name, CORE/COMMUNITY badge, version, author, description, and tool count preview

---

## [v1.1.1] ‚Äî 2026-02-23

### Added
- **üåê Galactic Browser (Chrome Extension)** ‚Äî Full Chrome extension with popup authentication, side panel chat with streaming responses, and real-time browser interaction via WebSocket bridge. 10 new browser tools: `chrome_navigate`, `chrome_read_page`, `chrome_screenshot`, `chrome_click`, `chrome_find`, `chrome_execute_js`, `chrome_tabs_list`, `chrome_form_input`, `chrome_get_page_text`, `chrome_scroll_to`. Content script provides accessibility tree snapshots, element finding, form interaction, and JavaScript execution in the user's real Chrome browser
- **üì± Social Media Plugin** ‚Äî Twitter/X integration via Tweepy (post tweets, reply, search mentions, get timeline) and Reddit integration via PRAW (submit posts, comment, search subreddits, read inbox). 8 new tools: `twitter_post`, `twitter_reply`, `twitter_search`, `twitter_mentions`, `reddit_post`, `reddit_comment`, `reddit_search`, `reddit_inbox`
- **üí∞ Actual Cost Tracking** ‚Äî CostTracker now supports `actual_cost` from OpenRouter's generation API, overriding local estimates for precise spend tracking
- **üìñ TOOLS.md Integration** ‚Äî Personality system now reads TOOLS.md for tool usage guidance, injected into every system prompt

### Fixed
- **üîß System-wide [No response] Fix** ‚Äî Root cause: cloud models (Gemini via OpenRouter) return tool calls via native `tool_calls` streaming field, but the streaming code only read `delta.content` ‚Üí empty response. Added native `tool_calls` capture in all 3 LLM call paths (streaming, non-streaming messages, non-streaming legacy). Streaming fix accumulates incremental arguments across multiple chunks
- **üì® Telegram Reliability Overhaul** ‚Äî Fixed `send_message` silently swallowing ALL errors (`except: pass`); added Markdown parse failure detection with automatic plain text fallback; added message splitting for Telegram's 4096-character limit; fixed `UnboundLocalError` crash on `CancelledError` (response variable not initialized); added `[No response]` guard in all 4 handler methods (`process_and_respond`, `_handle_document`, `_handle_photo`, `_handle_audio`); added `CancelledError` handling across all handlers
- **üîë WebSocket Auth Bypass for Localhost** ‚Äî `handle_stream()` in web_deck.py now bypasses token validation for localhost connections (`127.0.0.1`, `::1`), matching the auth middleware's localhost bypass. Fixes Chrome extension side panel red status dot
- **üí¨ Side Panel HTTP Fallback** ‚Äî sidepanel.js now reads HTTP response body from `/api/chat` as fallback when WebSocket `/stream` doesn't deliver chunks, ensuring responses always appear

---

## [v1.1.0] ‚Äî 2026-02-22

### Added
- **üåê OpenRouter Model Expansion (6 ‚Üí 26)** ‚Äî 26 curated models across 3 tiers: Frontier (Gemini 3.1 Pro, Claude Opus 4.6, GPT-5.2, Grok 4.1 Fast, DeepSeek V3.2, Qwen 3.5 Plus, GPT-5.2 Codex), Strong (12 models including Claude Sonnet 4.6, GPT-5.1, Kimi K2.5, GLM-5), Fast (7 models including Mistral Large, Devstral, MiniMax M2.5, Sonar Pro Search, Nemotron Nano 30B). All models added to Control Deck Models page and Telegram model menus
- **üí∞ Token Cost Dashboard** ‚Äî Real-time cost tracking in the Status tab with 6 summary cards (Session, Today, This Week, This Month, Last Request, Avg/Message), multi-currency support (USD, EUR, GBP, CAD, AUD, JPY, INR, BRL, KRW), persistent JSONL logging (`logs/cost_log.jsonl`), real token extraction from all providers (Google, Anthropic, OpenAI-compatible, Ollama), MODEL_PRICING for 33 models, free provider detection (NVIDIA, Cerebras, Groq, HuggingFace, Ollama show FREE), 90-day auto-prune
- **üìä CostTracker Backend** ‚Äî New `CostTracker` class in `gateway_v2.py` with append-only JSONL storage, session/daily/weekly/monthly aggregation, per-model breakdowns, `/api/cost-stats` endpoint
- **üí± Multi-Currency Support** ‚Äî 9 currencies with static exchange rates, currency selector saved to localStorage, all costs stored in USD with client-side conversion

### Fixed
- **üìà Chart.js Removal** ‚Äî Removed Chart.js CDN dependency that caused Chrome STATUS_BREAKPOINT crashes and infinite resize loops in the Status tab. Cost dashboard now uses lightweight summary cards only

---

## [v1.0.9] ‚Äî 2026-02-22

### Added
- **üé¨ Video Generation (Google Veo)** ‚Äî Text-to-video and image-to-video via Google Veo API. Two new tools: `generate_video` (text prompt ‚Üí MP4) and `generate_video_from_image` (still image ‚Üí animated MP4). Supports 4s/6s/8s duration, 720p/1080p/4K resolution, 16:9 and 9:16 aspect ratios, negative prompts. Async polling with status updates during generation
- **üé• Inline Video Player** ‚Äî Generated videos appear inline in the Control Deck chat as HTML5 `<video>` elements with controls, autoplay, muted loop, and a download link. New `/api/video/{filename}` serving endpoint
- **üì¶ New NVIDIA Models** ‚Äî Added Nemotron Super 49B (`nvidia/llama-3.3-nemotron-super-49b-v1.5`), Nemotron Nano 9B v2 (`nvidia/nvidia-nemotron-nano-9b-v2`), and Phi-3 Medium (`microsoft/phi-3-medium-4k-instruct`) to the Models page with model cards
- **üß† NVIDIA Thinking Model Params** ‚Äî Added per-model reasoning parameters for DeepSeek V3.2 and Nemotron Nano 9B v2 to the `_NVIDIA_THINKING_MODELS` configuration
- **üé¨ Multi-Provider Video Config** ‚Äî New `video:` config section with Google Veo day-one support and scaffolding for Runway Gen-4, Kling, and Luma Dream Machine

### Fixed
- **üí¨ Chat/Logs/Thinking Scroll** ‚Äî All three tabs now use conventional bottom-up chat ordering (newest content at bottom, like Facebook Messenger). Root cause: stream-bubble was the first child and `insertBefore(sb.nextSibling)` placed new messages at the top. Fixed by moving stream-bubble to be the last child and inserting before it. Also fixed log trim (now removes oldest, not newest) and filterLogs (removed reverse)
- **üîß NVIDIA Streaming Hang** ‚Äî Some NVIDIA models (Qwen 3.5 397B) accept streaming requests but never send SSE data. Added `_NVIDIA_NO_STREAM` set to force non-streaming, plus automatic streaming-to-non-streaming fallback for all NVIDIA models
- **‚è≥ NVIDIA Cold-Start Retry** ‚Äî Large NVIDIA models return HTTP 504 after ~5 minutes when cold-loading onto GPUs. Added auto-retry (up to 2 attempts) on 502/503/504 with 10s delay and "‚è≥ NVIDIA model loading" status messages
- **üì° NVIDIA Granular Timeouts** ‚Äî Changed from single 300s timeout to 30s connect + 600s read for large NVIDIA models that take several minutes to respond
- **üîó HuggingFace URL Migration** ‚Äî Updated from deprecated `api-inference.huggingface.co/v1` to `router.huggingface.co/v1` across gateway, web deck, and config
- **üìÑ Non-Streaming JSON Parsing** ‚Äî Hardened non-streaming response path with HTTP status check before parsing and safe handling of empty response bodies
- **‚ö° Bulletproof Shutdown** ‚Äî Added 8-second hard-exit timer that prevents infinite hang on shutdown; proper shutdown_event chain across all subsystems

---

## [v1.0.8] ‚Äî 2026-02-22

### Fixed
- **üîß Model Persistence ‚Äî Definitive Fix** ‚Äî Complete architectural overhaul of config save system. Root cause: `_save_config()` was a destructive full-file overwrite. Fix: safe read-modify-write pattern, defensive model-key writeback on every save, unified config paths via `self.core.config_path`, consolidated triple-save for toggle settings, startup diagnostics with `[config]`/`[DEFAULT]` source tags
- **üé® Imagen 4 Safety Filter** ‚Äî Fixed `400 INVALID_ARGUMENT` by changing `safety_filter_level` from `BLOCK_ONLY_HIGH` to `BLOCK_LOW_AND_ABOVE`
- **üñºÔ∏è Inline Image Display** ‚Äî Added diagnostic logging to image delivery pipeline, fixed `_rawText` accumulation bug between messages
- **üíæ Config Save Path Fixes** ‚Äî `handle_save_key()`, `handle_setup()`, `handle_login()`, and `model_manager._save_config()` all now use safe read-modify-write pattern with defensive model writeback

---

## [v1.0.7] ‚Äî 2026-02-21

### Added
- **üîΩ Shutdown/Restart Buttons** ‚Äî Control Deck now has shutdown and restart buttons for easy server management
- **üé® Imagen 4 SDK Migration** ‚Äî Migrated from legacy Gemini image API to the new `google-genai` SDK for Imagen 4 generation

### Fixed
- **üìú Scroll Ordering** ‚Äî Initial scroll ordering implementation (newest-first, later corrected in v1.0.9 to conventional bottom-up)
- **üé® SD3.5 NVIDIA Fix** ‚Äî Stable Diffusion 3.5 image generation restored on NVIDIA NIM
- **ü§ñ SubAgent Overhaul** ‚Äî Reworked SubAgentManager for reliability and proper task tracking

---

## [v1.0.6] ‚Äî 2026-02-21

### Fixed
- **üß† VAULT / Personality not loading** ‚Äî `config.yaml` ‚Üí `paths.workspace` was still pointing to the old OpenClaw workspace directory after install migration. The personality system (`personality.py`) reads VAULT.md, IDENTITY.md, USER.md, SOUL.md, and MEMORY.md from the workspace path. With the stale path, the AI had no access to the user's vault (credentials, personal data) and responded with "I don't have access to your personal credentials." Fixed by updating the workspace path to the current install directory
- **üéØ Smart routing misclassification of file uploads** ‚Äî When a user sends a document via Telegram (e.g., CHANGELOG.md, README.md), the entire file content was fed into `classify_task()` for smart routing. Any .md file describing code changes would contain keywords like "script", "function", "implement", triggering a "coding" classification and routing to the Qwen Coder 480B model ‚Äî even when the user wanted help with marketing or social media. `classify_task()` now strips attached file content and code blocks before classification, so routing is based on the user's actual message/caption, not file contents
- **‚è± Telegram timeout killing active tasks early** ‚Äî Telegram bridge had its own `timeout_seconds: 180` that wrapped `speak()` in a separate `asyncio.wait_for()`. The global `speak_timeout` is 600s, but Telegram's 180s limit killed the task before the gateway finished. `_get_speak_timeout()` now uses `max(global_timeout, telegram_timeout)` so the Telegram bridge never cuts off a task that the gateway is still allowed to work on

---

## [v1.0.5] ‚Äî 2026-02-21

### Added
- **üîå Agent Loop Circuit Breaker** ‚Äî After 3 consecutive tool failures (errors or timeouts), the AI is forced to stop calling tools and explain the situation to the user instead of spiraling through all 50 turns
- **‚ö†Ô∏è Progressive Backpressure** ‚Äî At 50% and 80% of the tool-turn budget, the AI receives nudge messages telling it to wrap up and deliver results, preventing runaway automation sessions
- **üîÑ Tool Repetition Guard** ‚Äî If the same tool is called 4+ times in a 6-call window without progress, the AI is instructed to change strategy or explain the problem
- **üîí Model Lock During Active Tasks** ‚Äî Switching models via the Control Deck while the AI is mid-task now queues the switch instead of disrupting the active conversation (applied automatically after the task completes)
- **üéØ Smart Routing Restoration** ‚Äî When smart routing temporarily switches to a specialized model (e.g., Qwen Coder for coding tasks), the original model is now automatically restored after the request completes

### Fixed
- **Agent timeout spiral** ‚Äî Complex tasks (like script creation) could burn through all 50 tool turns without converging, hitting the 600s wall-clock timeout. The new anti-spin guardrails (circuit breaker, backpressure, repetition guard) prevent this pattern
- **Smart routing model leak** ‚Äî `auto_route()` switched the model but never restored it, so the specialized model stuck around for subsequent unrelated requests

---

## [v1.0.4] ‚Äî 2026-02-21

### Fixed
- **üîß Model persistence across restarts** ‚Äî Selected primary model now survives restarts. Two bugs were causing the model to revert to Gemini 2.5 Flash on every startup:
  1. `/api/switch_model` (used by the Models tab quick-switch) updated the live session only ‚Äî it never wrote the selection to `config.yaml`. It now calls `ModelManager._save_config()` so the choice is immediately persisted.
  2. `GalacticGateway.__init__` read `config.gateway.model` which was only written by the Settings tab path, not the Models tab path. It now reads `config.models.primary_model` first (the canonical value written by `ModelManager`), falling back to `config.gateway.model`, so startup always loads the correct last-used model regardless of which UI element made the switch.

---

## [v1.0.3] ‚Äî 2026-02-21

### Added
- **üé§ Voice Input Button** ‚Äî Microphone button in the Control Deck chat bar. Click to record, sends audio to Whisper (OpenAI/Groq) for transcription, inserts text into the chat input automatically
- **üî• Auto Windows Firewall Rule** ‚Äî On startup with `remote_access: true`, Galactic AI automatically adds a Windows Firewall inbound rule allowing TCP traffic on the Control Deck port (private networks only)
- **"CONTROL DECK" label** in the top bar next to the model status badge

### Fixed
- **Remote access HTTP mode** ‚Äî Server now binds to `0.0.0.0` on plain HTTP instead of HTTPS with self-signed TLS. Self-signed certs caused `ERR_EMPTY_RESPONSE`. JWT authentication still protects all remote API endpoints
- **Updater em dash encoding** ‚Äî Fixed `update.ps1` parse error caused by em dash character corruption in some environments

---

## [v1.0.2] ‚Äî 2026-02-21

### Added
- **Localhost bypass for remote auth** ‚Äî Local connections from `127.0.0.1`/`::1` bypass JWT auth so the PC is never locked out of the Control Deck when `remote_access: true`
- **"CONTROL DECK" label** in top bar (first introduced here, improved in v1.0.3)

### Fixed
- **QR code compatibility** ‚Äî QR pairing code now uses standard black-on-white colors with higher error correction (`ERROR_CORRECT_H`)
- **Test Voice button now plays audio** ‚Äî Previously only generated the MP3 server-side without streaming it back. Now uses `/api/tts` to stream audio bytes to the browser and plays them directly
- **Desktop shortcut icon** ‚Äî `galactic_ai_flux_v4.ico` added to the repository (was missing, referenced by `create_shortcut.ps1`)

---

## [v1.0.1] ‚Äî 2026-02-21

### Added
- **Config auto-migration** ‚Äî On startup, `load_config()` detects missing config sections from newer versions and adds them with safe defaults. Affected sections: `gmail`, `discord`, `whatsapp`, `webhooks`, `web`, `elevenlabs`, `models`, `tool_timeouts`, `aliases`. Existing values are never overwritten
- **Updater `-Force` flag** ‚Äî `.\update.ps1 -Force` and `./update.sh --force` re-download even when the installed version matches the latest release

### Fixed
- Missing release ZIP assets ‚Äî Added `windows.zip`, `macos.zip`, `linux.tar.gz`, `universal.zip`, and `SHA256SUMS.txt`

---

## [v1.0.0] ‚Äî 2026-02-21

### Added
- **üåê Remote Access Mode** ‚Äî Access Galactic AI from anywhere
  - Enable with `remote_access: true` in config.yaml
  - Auto-generated self-signed TLS certificates (HTTPS)
  - Binds to `0.0.0.0` for LAN/internet access
  - Startup warning when remote access is active
- **üîë JWT Authentication** ‚Äî Enterprise-grade auth for remote connections
  - HMAC-SHA256 signed tokens with 24-hour expiry
  - Auto-generated 64-character hex secret stored in config.yaml
  - Auth middleware on all `/api/*` endpoints
  - WebSocket authentication via query parameter
  - Backward-compatible with existing password hash for local mode
- **üõ°Ô∏è Rate Limiting** ‚Äî Brute-force protection
  - 60 requests/minute per IP for API endpoints
  - 5 login attempts/minute per IP
  - Returns 429 with `Retry-After` header
- **üîí CORS Middleware** ‚Äî Cross-origin protection with configurable allowed origins
- **üéôÔ∏è Voice API Endpoints**:
  - `POST /api/tts` ‚Äî text-to-speech via existing ElevenLabs/edge-tts/gTTS pipeline, returns MP3
  - `POST /api/stt` ‚Äî speech-to-text via OpenAI Whisper with Groq Whisper fallback, accepts multipart audio
- **`remote_access.py`** ‚Äî New security module centralizing JWT, rate limiting, CORS, and auth middleware

### Fixed
- **Settings model save bug** ‚Äî Changing primary/fallback models in the Settings tab now takes effect immediately
  - `switch_to_primary()` no longer short-circuits when already in primary mode
  - `_save_config()` now syncs gateway provider/model in config.yaml for persistence across restarts

### Changed
- Version bumped from v0.9.3 to v1.0.0 across all files
- `web_deck.py` login endpoint returns JWT tokens when remote access is enabled
- `web_deck.py` JavaScript uses `authFetch()` wrapper for JWT auth headers on all API calls
- `web_deck.py` WebSocket uses `wss://` protocol when on HTTPS
- `galactic_core_v2.py` auto-generates JWT secret on first remote-mode startup
- Website `index.html` updated with remote access section

---

## [v0.9.3] ‚Äî 2026-02-21

### Added
- **‚öôÔ∏è Settings Tab** ‚Äî New Control Deck tab with three sections:
  - *Model Configuration* ‚Äî Primary and fallback provider+model dropdowns (populated from all 100+ models), auto-fallback toggle, smart routing toggle, streaming toggle
  - *Voice* ‚Äî TTS voice dropdown with all 7 voices + Test Voice button
  - *System* ‚Äî GitHub update check interval, speak() timeout, max ReAct turns
  - All settings saved immediately to `config.yaml` via new API endpoints
- **üîê VAULT.md** ‚Äî Private credentials file for automation tasks
  - `VAULT-example.md` template included in repository
  - Loaded by `personality.py` into every system prompt with "never share or expose" instruction
  - Gitignored and protected by both `update.ps1` and `update.sh`
  - Editable in the Memory tab of the Control Deck
- **üó£Ô∏è TTS Voice Selector** ‚Äî Quick Tools sidebar dropdown for instant voice switching (Guy, Aria, Jenny, Davis, Nova, Byte, gTTS)
- **üÜï GitHub Auto-Update Checker** ‚Äî Background task checks `cmmchsvc-dev/Galactic-AI` releases every 6 hours (configurable, 0 = disabled). Shows dismissible banner + 30-second toast in Control Deck when update available
- **üîΩ Model Dropdowns** ‚Äî PER-MODEL OVERRIDES now uses `<select>` dropdown populated from ALL_MODELS instead of a text input. Custom model text input provided as fallback
- **3 new API endpoints**: `POST /api/settings/models`, `POST /api/settings/voice`, `POST /api/settings/system`
- **`voice` and `update_check_interval`** fields added to `/api/status` response
- **VAULT.md** added to workspace file lists in Memory tab (OpenClaw migration, file list, auto-create defaults)
- **`system.update_check_interval: 21600`** added to `config.yaml`

### Changed
- Settings tab allows switching primary/fallback models without leaving the browser ‚Äî no more editing `config.yaml` manually
- `personality.py` `get_system_prompt()` now loads VAULT.md as the 5th injected file
- `galactic_core_v2.py` `imprint_workspace()` now includes VAULT.md in the workspace files list
- `update.ps1` and `update.sh` protected file lists updated to include VAULT.md
- `.gitignore` updated to explicitly list VAULT.md
- Website `index.html` updated to v0.9.3 with new features section
- `docs/ARCHITECTURE.md` fully rewritten to reflect v0.9.3 system design
- Tool count updated to 100+ across README, FEATURES, and website

---

## [v0.9.2] ‚Äî 2026-02-20

### Added
- **Resilient model fallback chain** ‚Äî Error-type-specific cooldowns (RATE_LIMIT: 60s, SERVER_ERROR: 30s, TIMEOUT: 10s, AUTH_ERROR: 86400s, QUOTA_EXHAUSTED: 3600s)
- **Automatic provider recovery** ‚Äî Background loop retests failed providers after cooldown expires
- **16 new built-in tools** (108 total):
  - Archives: `zip_create`, `zip_extract`
  - HTTP: `http_request` (raw REST with custom headers)
  - Environment: `env_get`, `env_set`
  - Window management: `window_list`, `window_focus`, `window_resize`
  - System: `system_info`, `kill_process_by_name`
  - Utilities: `qr_generate`, `color_pick`, `text_transform` (15 text operations)
  - Notifications: `notify` (desktop toast/balloon)
  - Clipboard: `clipboard_get`, `clipboard_set`
- **Expanded Status screen** ‚Äî 30+ telemetry fields across 6 sections (Model, Fallback Chain, Runtime, Memory, Tokens, Plugins)
- **speak() wall-clock timeout** ‚Äî Entire ReAct loop wrapped in `asyncio.wait_for()`, default 600s, configurable via `models.speak_timeout`
- **Per-tool configurable timeouts** in `config.yaml` under `tool_timeouts` (exec_shell: 120s, execute_python: 60s, generate_image: 180s)
- **Shell command timeout** in ShellExecutor plugin
- **`model_fallback` WebSocket event** ‚Äî Control Deck shows toast notification when provider falls back
- **Toast notification system** ‚Äî CSS-animated popups for model fallback events

### Changed
- `config.yaml` expanded with `tool_timeouts`, `speak_timeout`, `fallback_cooldowns` sections
- Status tab HTML redesigned with 6 organized sections

---

## [v0.9.1] ‚Äî 2026-02-14

### Added
- **Organized image folders** ‚Äî Generated images saved to date-stamped subdirectories
- **Structured logging system** ‚Äî Daily JSON component logs alongside plain-text system_log.txt
- **Log rotation** ‚Äî Files trimmed at 2MB / 5000 lines

### Changed
- Log system backwards-compatible ‚Äî existing callers unchanged

---

## [v0.9.0] ‚Äî 2026-02-10

### Added
- **Discord bridge** ‚Äî Full bot integration with slash commands, typing indicators, allowed-channel access control
- **WhatsApp bridge** ‚Äî Meta Cloud API webhook integration
- **Gmail bridge** ‚Äî IMAP inbox monitoring with Telegram notifications
- **Imagen 4 / Imagen 4 Ultra** ‚Äî Google Imagen 4 image generation tools (`generate_image_gemini`, `generate_image_gemini_ultra`)
- **Imagen 4 Fast** ‚Äî Fast variant via Gemini API
- **Telegram image model selector** ‚Äî `/model` ‚Üí Image Models in Telegram to switch between Imagen 4 Ultra, Imagen 4, FLUX.1 Dev, Imagen 4 Fast, FLUX.1 Schnell
- **Thinking tab persistence** ‚Äî Agent trace buffered in memory (last 500 entries), restored on page load via `/api/traces`
- **Chat timestamps** ‚Äî HH:MM:SS timestamp on every message
- **All providers in Telegram model menu** ‚Äî 14 providers √ó their model lists in `/model` keyboard
- **Image attachment in chat** ‚Äî Attach images to chat messages for vision analysis

### Fixed
- Graceful shutdown ‚Äî single Ctrl+C now cleanly closes all subsystems
- Per-tool timeout ‚Äî 60s `asyncio.wait_for` on every tool call prevents "typing forever"

---

## [v0.8.1] ‚Äî 2026-01-28

### Fixed
- Typing indicator heartbeat ‚Äî no longer sends duplicate "typing" events
- Fast Ctrl+C shutdown ‚Äî no longer hangs waiting for Telegram long-poll to expire
- Duplicate message guard ‚Äî prevents double-processing of messages on slow connections

---

## [v0.8.0] ‚Äî 2026-01-20

### Added
- 17 new tools ‚Äî clipboard, notifications, window management, HTTP requests, QR codes, system info, text transforms, SD3.5 image gen, FLUX auto-generate
- FLUX.1 Schnell and FLUX.1 Dev image generation via NVIDIA NIM
- Stable Diffusion 3.5 Large image generation
- FLUX auto-generate mode ‚Äî typing any prompt generates an image when FLUX is selected

---

## [v0.7.9] ‚Äî 2026-01-12

### Added
- Image delivery to Telegram and Control Deck ‚Äî generated images sent as photos, not file paths
- Dual FLUX API keys ‚Äî separate keys for FLUX.1 Schnell and FLUX.1 Dev

---

## [v0.7.8] ‚Äî 2026-01-08

### Added
- 9 new NVIDIA models (Kimi K2.5, GLM5, MiniMax M2, Nemotron variants)
- Thinking model support (models that return `<thinking>` blocks)
- File attachment fix in chat

---

## [v0.7.7] ‚Äî 2025-12-28

### Added
- Accessibility-driven browser interactions ‚Äî click/type by accessibility ref ID
- Network request interception and response body capture

---

## [v0.7.6] ‚Äî 2025-12-20

### Added
- Desktop automation plugin (pyautogui) ‚Äî click, type, scroll, drag, template matching
- Clipboard tools

---

## [v0.7.5] ‚Äî 2025-12-14

### Added
- Sub-agent orchestration ‚Äî spawn parallel AI agents for multi-step workflows
- `SubAgentManager` plugin

---

## [v0.7.4] ‚Äî 2025-12-08

### Added
- Browser session save/restore ‚Äî persist cookies and storage state across runs
- Geolocation spoofing, proxy support, media emulation

---

## [v0.7.3] ‚Äî 2025-12-02

### Added
- Browser tracing (Playwright trace recording)
- Iframe support ‚Äî execute actions inside nested frames
- Browser storage tools (localStorage, sessionStorage)

---

## [v0.7.2] ‚Äî 2025-11-25

### Added
- NVIDIA single-key setup ‚Äî one key works for all NVIDIA-hosted models
- Quick-pick model chips in Control Deck
- Custom model text field for Ollama custom models
- Ollama 10-minute timeout for large local models

---

## [v0.7.1] ‚Äî 2025-11-18

### Added
- **Persistent memory** ‚Äî MEMORY.md + memory_aura.json
- **Voice I/O** ‚Äî Whisper transcription + TTS response via Telegram
- **Chat persistence** ‚Äî `logs/chat_history.jsonl`, restored on page load
- **Personality config** ‚Äî byte / custom / generic / files modes
- **One-command auto-updater** ‚Äî `update.ps1` and `update.sh`

---

## [v0.7.0] ‚Äî 2025-11-10

### Added
- 14 AI providers (added Cerebras, OpenRouter, HuggingFace, Together AI, Perplexity)
- TTS configuration in Setup Wizard
- OpenClaw migration step ‚Äî import existing memory/identity files

### Fixed
- Gemini duplicate response bug

---

## [v0.6.0-Alpha] ‚Äî 2025-10-28

### Initial public release
- 72 built-in tools
- 5 AI providers (Google, Anthropic, OpenAI, Groq, Ollama)
- Telegram bot
- Web Control Deck at localhost:17789
- ReAct agentic loop
- Playwright browser automation
